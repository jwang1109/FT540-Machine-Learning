{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3ab9b3c-432a-4e97-8555-f4ed7c4c61f2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# Fourth Assignment - FINTECH 540 - Machine Learning for FinTech - Dimensionality Reduction with Autoencoders\n",
    "\n",
    "In this assignment, you will attempt to replicate the S&P 500 index using the price series of some of its constituents. This task involves applying machine learning techniques, specifically neural networks, to select a subset of companies that tracks the index value well. You may also explore using a Principal Component Analysis (PCA) as a benchmarking tool, though this is not mandatory. The primary objective of this task is to achieve a satisfactory performance on the test set (out-of-sample). For a reference on the meaning of this exercise, refer to notebook 14 of our class material.\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "- **Asset Close Prices**: 360 stocks + S&P500 Index (Last column of both files) from 2000 to 2023.\n",
    "- **Format**: Divided into train and test sets (2 files are provided). Do not split again into train and test. Split only the train set if you want to obtain a validation set for hyperparameter selection.\n",
    "\n",
    "\n",
    "## Task and General Hints\n",
    "\n",
    "In this assignment, you are tasked with building an unsupervised learning model on equity data. Your primary goal is to ensure accurate out-of-sample reproduction of the given index (S&P500) through a subset of the constituents and evaluate them with the below-mentioned metric.\n",
    "\n",
    "To guide you through this process, consider breaking down your tasks into the following three phases:\n",
    "\n",
    "**Preprocessing**\n",
    "The dataset is already free of inconsistencies, missing values, or outliers. \n",
    "- **Data Splitting**: The dataset is partitioned, and two files are provided to you.\n",
    "\n",
    "**Model Selection**\n",
    "- This notebook focuses on using neural networks for index replication. You can experiment with the different neural network architectures (autoencoders) we have seen in class. Feel free to compare the performance against a PCA methodology. \n",
    "\n",
    "**Model Tuning and Evaluation**\n",
    "- Once you've selected a model, you'll want to fine-tune its parameters to achieve a good index tracking out-of-sample. You must also choose the number of companies used to reproduce the index dynamics.\n",
    "- You may adjust parameters manually or construct a routine to fit several models with different hyperparameters. \n",
    "- Evaluate your final model using the function provided at the end of the notebook, paying attention to respect the indicated naming convention.\n",
    "\n",
    "**Note**: Parameter choices and tuning should be made thoughtfully while it is up to you. Carefully study the documentation of the neural network models and refer to the Jupyer Notebooks we used in class to see the possible parameters you can fine-tune.\n",
    "\n",
    "**IMPORTANT REMARK**: \n",
    "You must use the test set solely as data the model has never seen before. The results on that part of the dataset are those that are going to provide your grade.\n",
    "\n",
    "Remember to set the seed when training and instantiating your model. You can use either Keras (Tensorflow) or Pytorch for this task, and you must make your results fully reproducible for grading. Double-check that you have correctly set the seed before diving into the coding part.\n",
    "\n",
    "- [Setting the seed in Keras](https://www.tensorflow.org/api_docs/python/tf/keras/utils/set_random_seed)\n",
    "- [Setting the seed in Pytorch](https://pytorch.org/docs/stable/notes/randomness.html)\n",
    "\n",
    "# Grading Rubric\n",
    "\n",
    "Your grade for this assignment will be determined by a composite score that considers both the **normalized Root Mean Squared Error (RMSE)** on the test set and the **efficiency of your index reconstruction**. The formula for your final grade is as follows:\n",
    "\n",
    "$$ \\text{Final Score} = \\text{Weighted RMSE Score} + \\text{Weighted Efficiency Score} $$\n",
    "\n",
    "This will be a number between 0 and 100, with grades potentially curved before release.\n",
    "\n",
    "**Components of the Grading Rubric**\n",
    "\n",
    "1. **RMSE Score:**\n",
    "   - Calculated as:\n",
    "     $$ \\text{Normalized RMSE} = 1 - \\left( \\frac{\\text{RMSE}}{\\text{MAX_POSSIBLE_RMSE}} \\right) $$\n",
    "   - `MAX_POSSIBLE_RMSE` is set as the standard deviation of the target variable.\n",
    "   - RMSE measures how close your constructed index is to the actual index.\n",
    "   - This component contributes 70% to your final score.\n",
    "\n",
    "2. **Efficiency Score:**\n",
    "   - Calculated as:\n",
    "     $$ \\text{Efficiency Score} = 1 - \\left( \\frac{\\text{Number of Companies Used}}{\\text{Total Number of Companies}} \\right) $$\n",
    "   - Encourages models that use fewer companies for index replication. The more companies you use, the more costly it would be to construct that portfolio to track the S&P500, so the less, the better.\n",
    "   - This component contributes 30% to your final score.\n",
    "\n",
    "The final score is a weighted sum of the RMSE and Efficiency scores:\n",
    "\n",
    "$$ \\text{Final Score} = (\\text{Weight RMSE} \\times \\text{Normalized RMSE}) + (\\text{Weight Efficiency} \\times \\text{Efficiency Score}) $$\n",
    "\n",
    "Where:\n",
    "- `Weight RMSE` = 0.7 \n",
    "- `Weight Efficiency` = 0.3\n",
    "\n",
    "The final grade will be:\n",
    "\n",
    "$$ \\text{Grade} = \\lceil \\text{Final Score} \\times 100 \\rceil $$\n",
    "\n",
    "Rounded up to the nearest whole number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c42090-8cb2-4494-a2d1-25d6bc73efa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "# from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense, Activation, Input\n",
    "import os\n",
    "import random\n",
    "# Set the random seed for reproducibility\n",
    "def set_seed(seed_value):\n",
    "    os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    tf.random.set_seed(seed_value)\n",
    "\n",
    "# Example: Set the seed\n",
    "set_seed(42)\n",
    "\n",
    "load_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5d20f4-c455-4795-9f06-418770a79dc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def evaluate_index_performance(y_test, y_pred, num_companies_used, total_companies=360, weight_rmse=0.7, weight_efficiency=0.3):\n",
    "    \"\"\"\n",
    "    Function to evaluate the performance of the reconstructed index.\n",
    "    \n",
    "    :param y_test: Actual index values (out of sample)\n",
    "    :param y_pred: Predicted index values using a subset of companies\n",
    "    :param num_companies_used: Number of companies used for the reconstruction\n",
    "    :param total_companies: Total number of companies in the index (default 500 for S&P 500)\n",
    "    :param weight_mse: Weight for the MSE score (default 0.7)\n",
    "    :param weight_efficiency: Weight for the efficiency score (default 0.3)\n",
    "    :return: A composite score combining MSE and efficiency\n",
    "    \"\"\"\n",
    "    # Calculate MSE and normalized MSE score\n",
    "    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
    "    max_possible_rmse = y_test.std()\n",
    "    rmse_score = 1 - rmse / max_possible_rmse\n",
    "\n",
    "    # Calculate efficiency score\n",
    "    efficiency_score = 1 - (num_companies_used / total_companies)\n",
    "\n",
    "    # Calculate final grade\n",
    "    final_score = weight_rmse * rmse_score + weight_efficiency * efficiency_score\n",
    "\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5d6e98-2b4d-4c16-ab0d-06c7870ad09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read data\n",
    "train_df = pd.read_csv('sp_train.csv')\n",
    "test_df = pd.read_csv('sp_test.csv')\n",
    "assets_names = train_df.iloc[:,1:-1].columns\n",
    "index_train = train_df['S&P']\n",
    "X_train = train_df[assets_names]\n",
    "index_test = test_df['S&P']\n",
    "X_test = test_df[assets_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deec5aa6-0167-4acb-b09e-707f26ad0fc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler = MinMaxScaler((0, 1))\n",
    "# Stocks data\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Index data\n",
    "scaler_index = MinMaxScaler((0, 1))\n",
    "index_train = scaler_index.fit_transform(index_train.values.reshape(-1, 1))\n",
    "index_test = scaler_index.transform(index_test.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9720add-b0cb-4b73-b532-71e8c93f9061",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4629, 360)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e147aac6-0c65-4f6b-88ff-43a494577903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145/145 [==============================] - 1s 4ms/step\n",
      "37/37 [==============================] - 0s 3ms/step\n",
      "145/145 [==============================] - 0s 3ms/step\n",
      "37/37 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "## Deep Autoencoder - Tensorflow    \n",
    "# Network hyperparameters\n",
    "n_inputs = X_train.shape[1]\n",
    "    \n",
    "# Training hyperparameters\n",
    "epochs = 200\n",
    "batch_size = 10000\n",
    "    \n",
    "\n",
    "# Define model\n",
    "input_layer = Input(shape=(n_inputs,)) # input\n",
    "# Encoder Layers\n",
    "encoded = Dense(1024, activation='relu',activity_regularizer=tf.keras.regularizers.l2(10e-7))(input_layer)  # First encoder layer with ReLU activation\n",
    "encoded = Dense(512, activation='relu')(encoded)     # Second encoder layer with linear activation\n",
    "encoded = Dense(256, activation='relu')(encoded) # code\n",
    "# Decoder Layers\n",
    "decoded = Dense(512, activation='relu')(encoded)       # First decoder layer with ReLU activation\n",
    "decoded = Dense(1024, activation='relu')(decoded)       # Second decoder layer with ReLU activation\n",
    "\n",
    "decoded = Dense(n_inputs, activation='linear')(decoded) \n",
    "\n",
    "# Autoencoder\n",
    "model = Model(input_layer, decoded)\n",
    "    \n",
    "# Compile autoencoder\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# Fit the model\n",
    "history = model.fit(X_train,\n",
    "                    X_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    verbose=0\n",
    "                    )\n",
    "    \n",
    "\n",
    "# Visualize training loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# Obtain reconstruction of the stocks\n",
    "X_train_pred = model.predict(X_train)\n",
    "X_test_pred = model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# Obtain reconstruction of the stocks\n",
    "X_train_pred = model.predict(X_train)\n",
    "X_test_pred = model.predict(X_test)\n",
    "\n",
    "error = np.mean(np.abs(X_train - X_train_pred)**2, axis=0)\n",
    "#print('Training MSE: %.8f' %np.mean(error))\n",
    "\n",
    "error_test = np.mean(np.abs(X_test - X_test_pred)**2, axis=0)\n",
    "#print('Testing MSE: %.8f' %np.mean(error_test))\n",
    "    \n",
    "    \n",
    "# Sort stocks by reconstruction error\n",
    "ind = np.argsort(error)\n",
    "sort_error = error[ind]\n",
    "sort_assets_names = assets_names[ind]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86939f13-cef4-4703-89cb-8c3654eab2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_test = index_test.squeeze()# to facilitate evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d694e1-749f-45d1-a46b-a376fcc2140f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grade is 96.00, The number of stocks is 1\n",
      "The grade is 94.00, The number of stocks is 2\n",
      "The grade is 94.00, The number of stocks is 3\n",
      "The grade is 93.00, The number of stocks is 4\n",
      "The grade is 92.00, The number of stocks is 5\n",
      "The grade is 92.00, The number of stocks is 6\n",
      "The grade is 91.00, The number of stocks is 7\n",
      "The grade is 92.00, The number of stocks is 8\n",
      "The grade is 92.00, The number of stocks is 9\n",
      "The grade is 89.00, The number of stocks is 10\n",
      "The grade is 89.00, The number of stocks is 11\n",
      "The grade is 91.00, The number of stocks is 12\n",
      "The grade is 90.00, The number of stocks is 13\n",
      "The grade is 90.00, The number of stocks is 14\n",
      "The grade is 77.00, The number of stocks is 15\n",
      "The grade is 77.00, The number of stocks is 16\n",
      "The grade is 78.00, The number of stocks is 17\n",
      "The grade is 78.00, The number of stocks is 18\n",
      "The grade is 79.00, The number of stocks is 19\n",
      "The grade is 80.00, The number of stocks is 20\n",
      "The grade is 81.00, The number of stocks is 21\n",
      "The grade is 83.00, The number of stocks is 22\n",
      "The grade is 83.00, The number of stocks is 23\n",
      "The grade is 83.00, The number of stocks is 24\n",
      "The grade is 82.00, The number of stocks is 25\n",
      "The grade is 82.00, The number of stocks is 26\n",
      "The grade is 83.00, The number of stocks is 27\n",
      "The grade is 74.00, The number of stocks is 28\n",
      "The grade is 74.00, The number of stocks is 29\n",
      "The grade is 75.00, The number of stocks is 30\n",
      "The grade is 75.00, The number of stocks is 31\n",
      "The grade is 76.00, The number of stocks is 32\n",
      "The grade is 76.00, The number of stocks is 33\n",
      "The grade is 76.00, The number of stocks is 34\n",
      "The grade is 75.00, The number of stocks is 35\n",
      "The grade is 74.00, The number of stocks is 36\n",
      "The grade is 74.00, The number of stocks is 37\n",
      "The grade is 74.00, The number of stocks is 38\n",
      "The grade is 75.00, The number of stocks is 39\n",
      "The grade is 74.00, The number of stocks is 40\n",
      "The grade is 75.00, The number of stocks is 41\n",
      "The grade is 75.00, The number of stocks is 42\n",
      "The grade is 75.00, The number of stocks is 43\n",
      "The grade is 75.00, The number of stocks is 44\n",
      "The grade is 76.00, The number of stocks is 45\n",
      "The grade is 76.00, The number of stocks is 46\n",
      "The grade is 76.00, The number of stocks is 47\n",
      "The grade is 76.00, The number of stocks is 48\n",
      "The grade is 76.00, The number of stocks is 49\n",
      "The grade is 73.00, The number of stocks is 50\n",
      "The grade is 73.00, The number of stocks is 51\n",
      "The grade is 72.00, The number of stocks is 52\n",
      "The grade is 72.00, The number of stocks is 53\n",
      "The grade is 73.00, The number of stocks is 54\n",
      "The grade is 73.00, The number of stocks is 55\n",
      "The grade is 73.00, The number of stocks is 56\n",
      "The grade is 73.00, The number of stocks is 57\n",
      "The grade is 73.00, The number of stocks is 58\n",
      "The grade is 73.00, The number of stocks is 59\n",
      "The grade is 73.00, The number of stocks is 60\n",
      "The grade is 73.00, The number of stocks is 61\n",
      "The grade is 73.00, The number of stocks is 62\n",
      "The grade is 73.00, The number of stocks is 63\n",
      "The grade is 72.00, The number of stocks is 64\n",
      "The grade is 68.00, The number of stocks is 65\n",
      "The grade is 68.00, The number of stocks is 66\n",
      "The grade is 68.00, The number of stocks is 67\n",
      "The grade is 67.00, The number of stocks is 68\n",
      "The grade is 68.00, The number of stocks is 69\n",
      "The grade is 68.00, The number of stocks is 70\n",
      "The grade is 66.00, The number of stocks is 71\n",
      "The grade is 66.00, The number of stocks is 72\n",
      "The grade is 66.00, The number of stocks is 73\n",
      "The grade is 66.00, The number of stocks is 74\n",
      "The grade is 66.00, The number of stocks is 75\n",
      "The grade is 66.00, The number of stocks is 76\n",
      "The grade is 67.00, The number of stocks is 77\n",
      "The grade is 67.00, The number of stocks is 78\n",
      "The grade is 67.00, The number of stocks is 79\n",
      "The grade is 67.00, The number of stocks is 80\n",
      "The grade is 66.00, The number of stocks is 81\n",
      "The grade is 66.00, The number of stocks is 82\n",
      "The grade is 66.00, The number of stocks is 83\n",
      "The grade is 66.00, The number of stocks is 84\n",
      "The grade is 65.00, The number of stocks is 85\n",
      "The grade is 65.00, The number of stocks is 86\n",
      "The grade is 66.00, The number of stocks is 87\n",
      "The grade is 66.00, The number of stocks is 88\n",
      "The grade is 66.00, The number of stocks is 89\n",
      "The grade is 65.00, The number of stocks is 90\n",
      "The grade is 65.00, The number of stocks is 91\n",
      "The grade is 65.00, The number of stocks is 92\n",
      "The grade is 65.00, The number of stocks is 93\n",
      "The grade is 65.00, The number of stocks is 94\n",
      "The grade is 65.00, The number of stocks is 95\n",
      "The grade is 65.00, The number of stocks is 96\n",
      "The grade is 64.00, The number of stocks is 97\n",
      "The grade is 64.00, The number of stocks is 98\n",
      "The grade is 64.00, The number of stocks is 99\n",
      "The grade is 64.00, The number of stocks is 100\n",
      "The grade is 64.00, The number of stocks is 101\n",
      "The grade is 64.00, The number of stocks is 102\n",
      "The grade is 63.00, The number of stocks is 103\n",
      "The grade is 63.00, The number of stocks is 104\n",
      "The grade is 62.00, The number of stocks is 105\n",
      "The grade is 62.00, The number of stocks is 106\n",
      "The grade is 62.00, The number of stocks is 107\n",
      "The grade is 62.00, The number of stocks is 108\n",
      "The grade is 61.00, The number of stocks is 109\n",
      "The grade is 61.00, The number of stocks is 110\n",
      "The grade is 61.00, The number of stocks is 111\n",
      "The grade is 60.00, The number of stocks is 112\n",
      "The grade is 60.00, The number of stocks is 113\n",
      "The grade is 60.00, The number of stocks is 114\n",
      "The grade is 60.00, The number of stocks is 115\n",
      "The grade is 60.00, The number of stocks is 116\n",
      "The grade is 60.00, The number of stocks is 117\n",
      "The grade is 60.00, The number of stocks is 118\n",
      "The grade is 60.00, The number of stocks is 119\n",
      "The grade is 60.00, The number of stocks is 120\n",
      "The grade is 60.00, The number of stocks is 121\n",
      "The grade is 60.00, The number of stocks is 122\n",
      "The grade is 60.00, The number of stocks is 123\n",
      "The grade is 61.00, The number of stocks is 124\n",
      "The grade is 61.00, The number of stocks is 125\n",
      "The grade is 60.00, The number of stocks is 126\n",
      "The grade is 60.00, The number of stocks is 127\n",
      "The grade is 60.00, The number of stocks is 128\n",
      "The grade is 60.00, The number of stocks is 129\n",
      "The grade is 60.00, The number of stocks is 130\n",
      "The grade is 59.00, The number of stocks is 131\n",
      "The grade is 59.00, The number of stocks is 132\n",
      "The grade is 59.00, The number of stocks is 133\n",
      "The grade is 58.00, The number of stocks is 134\n",
      "The grade is 58.00, The number of stocks is 135\n",
      "The grade is 58.00, The number of stocks is 136\n",
      "The grade is 58.00, The number of stocks is 137\n",
      "The grade is 58.00, The number of stocks is 138\n",
      "The grade is 58.00, The number of stocks is 139\n",
      "The grade is 57.00, The number of stocks is 140\n",
      "The grade is 57.00, The number of stocks is 141\n",
      "The grade is 57.00, The number of stocks is 142\n",
      "The grade is 56.00, The number of stocks is 143\n",
      "The grade is 56.00, The number of stocks is 144\n",
      "The grade is 56.00, The number of stocks is 145\n",
      "The grade is 56.00, The number of stocks is 146\n",
      "The grade is 56.00, The number of stocks is 147\n",
      "The grade is 56.00, The number of stocks is 148\n",
      "The grade is 56.00, The number of stocks is 149\n",
      "The grade is 56.00, The number of stocks is 150\n",
      "The grade is 56.00, The number of stocks is 151\n",
      "The grade is 56.00, The number of stocks is 152\n",
      "The grade is 55.00, The number of stocks is 153\n",
      "The grade is 55.00, The number of stocks is 154\n",
      "The grade is 54.00, The number of stocks is 155\n",
      "The grade is 54.00, The number of stocks is 156\n",
      "The grade is 54.00, The number of stocks is 157\n",
      "The grade is 54.00, The number of stocks is 158\n",
      "The grade is 54.00, The number of stocks is 159\n",
      "The grade is 54.00, The number of stocks is 160\n",
      "The grade is 54.00, The number of stocks is 161\n",
      "The grade is 53.00, The number of stocks is 162\n",
      "The grade is 53.00, The number of stocks is 163\n",
      "The grade is 52.00, The number of stocks is 164\n",
      "The grade is 52.00, The number of stocks is 165\n",
      "The grade is 52.00, The number of stocks is 166\n",
      "The grade is 51.00, The number of stocks is 167\n",
      "The grade is 52.00, The number of stocks is 168\n",
      "The grade is 51.00, The number of stocks is 169\n",
      "The grade is 50.00, The number of stocks is 170\n",
      "The grade is 50.00, The number of stocks is 171\n",
      "The grade is 50.00, The number of stocks is 172\n",
      "The grade is 50.00, The number of stocks is 173\n",
      "The grade is 48.00, The number of stocks is 174\n",
      "The grade is 48.00, The number of stocks is 175\n",
      "The grade is 48.00, The number of stocks is 176\n",
      "The grade is 48.00, The number of stocks is 177\n",
      "The grade is 48.00, The number of stocks is 178\n",
      "The grade is 48.00, The number of stocks is 179\n",
      "The grade is 47.00, The number of stocks is 180\n",
      "The grade is 47.00, The number of stocks is 181\n",
      "The grade is 47.00, The number of stocks is 182\n",
      "The grade is 47.00, The number of stocks is 183\n",
      "The grade is 46.00, The number of stocks is 184\n",
      "The grade is 46.00, The number of stocks is 185\n",
      "The grade is 45.00, The number of stocks is 186\n",
      "The grade is 45.00, The number of stocks is 187\n",
      "The grade is 45.00, The number of stocks is 188\n",
      "The grade is 44.00, The number of stocks is 189\n",
      "The grade is 44.00, The number of stocks is 190\n",
      "The grade is 43.00, The number of stocks is 191\n",
      "The grade is 43.00, The number of stocks is 192\n",
      "The grade is 42.00, The number of stocks is 193\n",
      "The grade is 42.00, The number of stocks is 194\n",
      "The grade is 42.00, The number of stocks is 195\n",
      "The grade is 42.00, The number of stocks is 196\n",
      "The grade is 42.00, The number of stocks is 197\n",
      "The grade is 42.00, The number of stocks is 198\n",
      "The grade is 42.00, The number of stocks is 199\n",
      "The grade is 42.00, The number of stocks is 200\n",
      "The grade is 42.00, The number of stocks is 201\n",
      "The grade is 41.00, The number of stocks is 202\n",
      "The grade is 41.00, The number of stocks is 203\n",
      "The grade is 41.00, The number of stocks is 204\n",
      "The grade is 41.00, The number of stocks is 205\n",
      "The grade is 40.00, The number of stocks is 206\n",
      "The grade is 40.00, The number of stocks is 207\n",
      "The grade is 40.00, The number of stocks is 208\n",
      "The grade is 39.00, The number of stocks is 209\n",
      "The grade is 39.00, The number of stocks is 210\n",
      "The grade is 39.00, The number of stocks is 211\n",
      "The grade is 39.00, The number of stocks is 212\n",
      "The grade is 39.00, The number of stocks is 213\n",
      "The grade is 39.00, The number of stocks is 214\n",
      "The grade is 38.00, The number of stocks is 215\n",
      "The grade is 38.00, The number of stocks is 216\n",
      "The grade is 37.00, The number of stocks is 217\n",
      "The grade is 37.00, The number of stocks is 218\n",
      "The grade is 36.00, The number of stocks is 219\n",
      "The grade is 36.00, The number of stocks is 220\n",
      "The grade is 36.00, The number of stocks is 221\n",
      "The grade is 36.00, The number of stocks is 222\n",
      "The grade is 36.00, The number of stocks is 223\n",
      "The grade is 36.00, The number of stocks is 224\n",
      "The grade is 36.00, The number of stocks is 225\n",
      "The grade is 36.00, The number of stocks is 226\n",
      "The grade is 36.00, The number of stocks is 227\n",
      "The grade is 35.00, The number of stocks is 228\n",
      "The grade is 35.00, The number of stocks is 229\n",
      "The grade is 35.00, The number of stocks is 230\n",
      "The grade is 35.00, The number of stocks is 231\n",
      "The grade is 34.00, The number of stocks is 232\n",
      "The grade is 34.00, The number of stocks is 233\n",
      "The grade is 34.00, The number of stocks is 234\n",
      "The grade is 34.00, The number of stocks is 235\n",
      "The grade is 34.00, The number of stocks is 236\n",
      "The grade is 34.00, The number of stocks is 237\n",
      "The grade is 34.00, The number of stocks is 238\n",
      "The grade is 33.00, The number of stocks is 239\n",
      "The grade is 33.00, The number of stocks is 240\n",
      "The grade is 33.00, The number of stocks is 241\n",
      "The grade is 33.00, The number of stocks is 242\n",
      "The grade is 32.00, The number of stocks is 243\n",
      "The grade is 32.00, The number of stocks is 244\n",
      "The grade is 32.00, The number of stocks is 245\n",
      "The grade is 32.00, The number of stocks is 246\n",
      "The grade is 31.00, The number of stocks is 247\n",
      "The grade is 31.00, The number of stocks is 248\n",
      "The grade is 30.00, The number of stocks is 249\n",
      "The grade is 30.00, The number of stocks is 250\n",
      "The grade is 30.00, The number of stocks is 251\n",
      "The grade is 30.00, The number of stocks is 252\n",
      "The grade is 29.00, The number of stocks is 253\n",
      "The grade is 29.00, The number of stocks is 254\n",
      "The grade is 29.00, The number of stocks is 255\n",
      "The grade is 29.00, The number of stocks is 256\n",
      "The grade is 29.00, The number of stocks is 257\n",
      "The grade is 28.00, The number of stocks is 258\n",
      "The grade is 28.00, The number of stocks is 259\n",
      "The grade is 28.00, The number of stocks is 260\n",
      "The grade is 28.00, The number of stocks is 261\n",
      "The grade is 28.00, The number of stocks is 262\n",
      "The grade is 28.00, The number of stocks is 263\n",
      "The grade is 28.00, The number of stocks is 264\n",
      "The grade is 28.00, The number of stocks is 265\n",
      "The grade is 28.00, The number of stocks is 266\n",
      "The grade is 28.00, The number of stocks is 267\n",
      "The grade is 28.00, The number of stocks is 268\n",
      "The grade is 27.00, The number of stocks is 269\n",
      "The grade is 27.00, The number of stocks is 270\n",
      "The grade is 26.00, The number of stocks is 271\n",
      "The grade is 25.00, The number of stocks is 272\n",
      "The grade is 25.00, The number of stocks is 273\n",
      "The grade is 24.00, The number of stocks is 274\n",
      "The grade is 24.00, The number of stocks is 275\n",
      "The grade is 23.00, The number of stocks is 276\n",
      "The grade is 23.00, The number of stocks is 277\n",
      "The grade is 22.00, The number of stocks is 278\n",
      "The grade is 22.00, The number of stocks is 279\n",
      "The grade is 22.00, The number of stocks is 280\n",
      "The grade is 22.00, The number of stocks is 281\n",
      "The grade is 21.00, The number of stocks is 282\n",
      "The grade is 22.00, The number of stocks is 283\n",
      "The grade is 21.00, The number of stocks is 284\n",
      "The grade is 21.00, The number of stocks is 285\n",
      "The grade is 21.00, The number of stocks is 286\n",
      "The grade is 21.00, The number of stocks is 287\n",
      "The grade is 21.00, The number of stocks is 288\n",
      "The grade is 20.00, The number of stocks is 289\n",
      "The grade is 20.00, The number of stocks is 290\n",
      "The grade is 20.00, The number of stocks is 291\n",
      "The grade is 20.00, The number of stocks is 292\n",
      "The grade is 19.00, The number of stocks is 293\n",
      "The grade is 19.00, The number of stocks is 294\n",
      "The grade is 19.00, The number of stocks is 295\n",
      "The grade is 19.00, The number of stocks is 296\n",
      "The grade is 19.00, The number of stocks is 297\n",
      "The grade is 19.00, The number of stocks is 298\n",
      "The grade is 19.00, The number of stocks is 299\n",
      "The grade is 19.00, The number of stocks is 300\n",
      "The grade is 19.00, The number of stocks is 301\n",
      "The grade is 18.00, The number of stocks is 302\n",
      "The grade is 18.00, The number of stocks is 303\n",
      "The grade is 18.00, The number of stocks is 304\n",
      "The grade is 18.00, The number of stocks is 305\n",
      "The grade is 17.00, The number of stocks is 306\n",
      "The grade is 17.00, The number of stocks is 307\n",
      "The grade is 17.00, The number of stocks is 308\n",
      "The grade is 17.00, The number of stocks is 309\n",
      "The grade is 17.00, The number of stocks is 310\n",
      "The grade is 17.00, The number of stocks is 311\n",
      "The grade is 17.00, The number of stocks is 312\n",
      "The grade is 17.00, The number of stocks is 313\n",
      "The grade is 16.00, The number of stocks is 314\n",
      "The grade is 16.00, The number of stocks is 315\n",
      "The grade is 16.00, The number of stocks is 316\n",
      "The grade is 15.00, The number of stocks is 317\n",
      "The grade is 15.00, The number of stocks is 318\n",
      "The grade is 15.00, The number of stocks is 319\n",
      "The grade is 14.00, The number of stocks is 320\n",
      "The grade is 14.00, The number of stocks is 321\n",
      "The grade is 14.00, The number of stocks is 322\n",
      "The grade is 13.00, The number of stocks is 323\n",
      "The grade is 13.00, The number of stocks is 324\n",
      "The grade is 13.00, The number of stocks is 325\n",
      "The grade is 13.00, The number of stocks is 326\n",
      "The grade is 13.00, The number of stocks is 327\n",
      "The grade is 12.00, The number of stocks is 328\n",
      "The grade is 12.00, The number of stocks is 329\n",
      "The grade is 12.00, The number of stocks is 330\n",
      "The grade is 12.00, The number of stocks is 331\n",
      "The grade is 12.00, The number of stocks is 332\n",
      "The grade is 11.00, The number of stocks is 333\n",
      "The grade is 11.00, The number of stocks is 334\n",
      "The grade is 11.00, The number of stocks is 335\n",
      "The grade is 11.00, The number of stocks is 336\n",
      "The grade is 11.00, The number of stocks is 337\n",
      "The grade is 11.00, The number of stocks is 338\n",
      "The grade is 11.00, The number of stocks is 339\n",
      "The grade is 11.00, The number of stocks is 340\n",
      "The grade is 11.00, The number of stocks is 341\n",
      "The grade is 11.00, The number of stocks is 342\n",
      "The grade is 11.00, The number of stocks is 343\n",
      "The grade is 10.00, The number of stocks is 344\n",
      "The grade is 10.00, The number of stocks is 345\n",
      "The grade is 10.00, The number of stocks is 346\n",
      "The grade is 9.00, The number of stocks is 347\n",
      "The grade is 9.00, The number of stocks is 348\n",
      "The grade is 9.00, The number of stocks is 349\n",
      "The grade is 9.00, The number of stocks is 350\n",
      "The grade is 9.00, The number of stocks is 351\n",
      "The grade is 9.00, The number of stocks is 352\n",
      "The grade is 8.00, The number of stocks is 353\n",
      "The grade is 8.00, The number of stocks is 354\n",
      "The grade is 8.00, The number of stocks is 355\n",
      "The grade is 7.00, The number of stocks is 356\n",
      "The grade is 7.00, The number of stocks is 357\n",
      "The grade is 7.00, The number of stocks is 358\n",
      "The grade is 6.00, The number of stocks is 359\n",
      "The grade is 6.00, The number of stocks is 360\n"
     ]
    }
   ],
   "source": [
    "#find the parameter that can produce the best grade\n",
    "best_result = {'grade':-1,'n_stocks':-1,'index_test':np.array,'outsample_test':np.array}\n",
    "for n in range(1,361,1):\n",
    "    \n",
    "    portfolio_train = X_train_pred[:, ind[:n]]\n",
    "    portfolio_test = X_test_pred[:, ind[:n]]\n",
    "    # Create portfolio in-sample\n",
    "    tracked_index_insample = np.mean(portfolio_train, axis=1)\n",
    "\n",
    "    # Create portfolio out-sample\n",
    "    tracked_index_outofsample = np.mean(portfolio_test, axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "    grade = evaluate_index_performance(index_test, tracked_index_outofsample, n)\n",
    "    if grade > best_result['grade']:\n",
    "\n",
    "        best_result['grade'] = grade\n",
    "        best_result['n_stocks'] = n \n",
    "        best_result['index_test'] = index_test\n",
    "        best_result['outsample_test'] = tracked_index_outofsample\n",
    "    print(f'The grade is {math.ceil(grade * 100):.2f}, The number of stocks is {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a078aa5e-a0cc-4b6b-becd-f202c40405ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#find the best result\n",
    "index_test = best_result['index_test']\n",
    "tracked_index_outofsample = best_result['outsample_test']\n",
    "n = best_result['n_stocks']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d33b67-700b-44ad-949c-d70ed2667150",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "**Instructions to let the next code cell run:**\n",
    "\n",
    "Before running the cell below, ensure the following:\n",
    "\n",
    "- The target variable of your problem has to be named exactly `index_test`, while the out-of-sample prediction variable has to be named `tracked_index_outofsample`. Store the number of companies to reconstruct the index dynamic in a variable called `n`. The calculation of the evaluation function relies on this naming convention to determine the final grade. Please make sure that both `index_test` and `tracked_index_outofsample` are numpy arrays of dimensionality (1158,) where 1158 is the length of the out-of-sample set. If the dimensions are different than that the following cell will not run.\n",
    "\n",
    "By adhering to these naming conventions, the grading cell can compute the final score without any issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35dd6ac5-e25f-4866-94b6-3773918dda59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The grade for this assignment is 96.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def evaluate_index_performance(y_test, y_pred, num_companies_used, total_companies=360, weight_rmse=0.7, weight_efficiency=0.3):\n",
    "    \"\"\"\n",
    "    Function to evaluate the performance of the reconstructed index.\n",
    "    \n",
    "    :param y_test: Actual index values (out of sample)\n",
    "    :param y_pred: Predicted index values using a subset of companies\n",
    "    :param num_companies_used: Number of companies used for the reconstruction\n",
    "    :param total_companies: Total number of companies in the index (default 500 for S&P 500)\n",
    "    :param weight_mse: Weight for the MSE score (default 0.7)\n",
    "    :param weight_efficiency: Weight for the efficiency score (default 0.3)\n",
    "    :return: A composite score combining MSE and efficiency\n",
    "    \"\"\"\n",
    "    # Calculate MSE and normalized MSE score\n",
    "    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))\n",
    "    max_possible_rmse = y_test.std()\n",
    "    rmse_score = 1 - rmse / max_possible_rmse\n",
    "\n",
    "    # Calculate efficiency score\n",
    "    efficiency_score = 1 - (num_companies_used / total_companies)\n",
    "\n",
    "    # Calculate final grade\n",
    "    final_score = weight_rmse * rmse_score + weight_efficiency * efficiency_score\n",
    "\n",
    "    return final_score\n",
    "\n",
    "grade = evaluate_index_performance(index_test, tracked_index_outofsample, n)\n",
    "print(f'The grade for this assignment is {math.ceil(grade * 100):.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classenv",
   "language": "python",
   "name": "classenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
