{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a093e9ec-92aa-4a45-bd1b-499c648b5f2e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "# First Assignment - FINTECH 540 - Machine Learning for FinTech\n",
    "\n",
    "In this assignment, you will gain hands-on experience applying linear models to financial market data. Specifically, you will work with time series prices of the 30 constituents of the *Dow Jones Industrial Average (DJIA)* Index. The dataset covers the period from June $2^{nd}$, 2017, through June $2^{nd}$, 2023. The price series of the ETF associated with the DJIA index is also provided, whose symbol is *DIA*. The dataset is uploaded on Sakai in the same place where you found this notebook.\n",
    "\n",
    "You will deal with three consecutive tasks, so in general, you can only perform a task if you have solved the previous one. You can obtain at most 100 points for this home assignment. The tasks are briefly summarized below, and you can find the relative prompt in each subsection of this notebook:\n",
    "- Build descriptive linear models (CAPM) for all the index constituents (*20 points*).\n",
    "- Select a subset of constituents and fit a predictive linear model to forecast the index value (*40 points*).\n",
    "- Repeat the linear modeling exercise using boostrapped returns (*40 points*).\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "You only need to write the final code between the `### START CODE HERE ###` and `### END CODE HERE ###` comments. You can create more cells to experiment with and prepare your final code at your convenience. Remember to put the final version of the code where it is asked. Before submitting, remember to fully run your notebook from the start to the end to ensure that there will be no runtime error. Avoiding following such guidelines will result in a decrease in the total points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77b438b-9bf5-4cdc-879a-49aa0e6dec56",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Task 1 - Build descriptive linear models (CAPM) for all the index constituents (*20 points*)\n",
    "\n",
    "The Capital Asset Pricing Model (CAPM) is represented as:\n",
    "\n",
    "$$R_i - R_f =   \\beta_i (R_m - R_f) + e_i$$\n",
    "\n",
    "Where:\n",
    "- $R_i$ is the return of the asset or security $i$.\n",
    "- $R_f$ is the risk-free rate, representing the return on a risk-free investment.\n",
    "- $\\beta_i$ is the beta of the asset $i$, which measures its sensitivity to market movements.\n",
    "- $R_m$ is the market portfolio's return (the index).\n",
    "- $e_i$ is the error term or residual representing unexplained variation in the asset's return.\n",
    "\n",
    "The CAPM equation helps estimate the return of an asset based on its risk relative to the market and the risk-free rate. You can calculate the daily risk-free rate by using the following formula.\n",
    "\n",
    "$$ r_{\\text{daily}} = \\left(1 + r_{\\text{annual}}\\right)^{\\frac{1}{365}} - 1 $$\n",
    "\n",
    "Where:\n",
    "- $r_{\\text{daily}}$ is the daily yield. It represents the expected daily return on investment.\n",
    "- $ r_{\\text{annual}} $ is the annual yield. It represents the expected annual return on investment.\n",
    "- The formula assumes daily compounding, meaning the investment's return is calculated daily over a year (365 days). It allows to do the modeling based on daily returns.\n",
    "\n",
    "For this task, you can use an annual yield of *5.482%* per the annualized U.S. 3-month Treasury Bill yield.\n",
    "\n",
    "To solve this part of the homework, you have to:\n",
    "- Compute the daily yield from the annualized provided in the prompt.\n",
    "- Prepared the data to fit the CAPM for each company in the DJIA index described above.\n",
    "- Fit the CAPM for each company and check the estimated sensitivity to market movements.\n",
    "- Select a subset of stocks sensitive to market movements between 0.85 and 1.15. Before including a symbol, ensure the estimated sensitivity is statistically significant. Store the symbols in a Python list before moving to the next task.\n",
    "\n",
    "Before performing the CAPM modeling, remember to split the dataset into a training set and a test set and use only the training set to perform Task 1. Use *2022-01-01* as a cutoff date. Ensure the cutoff date is included in the test set and not in the train set.\n",
    "\n",
    "**Motivation behind the task**\n",
    "\n",
    "Fitting individual CAPM models allows for a detailed assessment of each stock's risk profile. CAPM provides a systematic way to quantify the sensitivity of each stock's returns to market movements, as measured by the beta coefficient. This individual assessment is valuable because different stocks may exhibit varying levels of market sensitivity.\n",
    "\n",
    "Selecting stocks based on their beta values is usually a risk-based approach to portfolio construction. By choosing stocks with higher (lower) beta values, you are essentially selecting those that tend to exhibit greater (lower) price volatility in response to market fluctuations. This can be seen as a deliberate strategy to include riskier (safer) assets in the portfolio.\n",
    "\n",
    "This task will set the basis for selecting a subset of index constituents to be used for a predictive model. \n",
    "\n",
    "**Grading Criteria**\n",
    "\n",
    "- **Data Preparation (10 points)**: Points will be awarded for preparing the data appropriately for the modeling task.\n",
    "\n",
    "- **CAPM Model Fitting (10 points)**: Points will be awarded based on the correctness and completeness of the CAPM models, including accurate significance evaluation and the subset of stock selection based on the beta estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c65900a-6b26-442e-8b39-f7e838e8b806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NKE.N', 'CSCO.OQ', 'DIS.N', 'INTC.OQ', 'HD.N', 'UNH.N', 'MSFT.OQ', 'HON.OQ', 'CRM.N', 'IBM.N', 'MMM.N', 'AAPL.OQ', 'CAT.N', 'V.N', 'TRV.N']\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "#0.read and get to know my data\n",
    "data = pd.read_csv(\"dows_daily.csv\")\n",
    "\"\"\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"----------shape----------------\")\n",
    "print(data.shape)\n",
    "data.head(5)\n",
    "data.tail(5)\n",
    "\n",
    "#1.Data Preparation\n",
    "#1.0 check\n",
    "\n",
    "print(\"----------type check ----------------\")\n",
    "print(data.dtypes) \n",
    "\n",
    "print(\"----------null value check-----------\")\n",
    "print(\"null value detected:\\n\",format(data.isnull().sum())) \n",
    "\n",
    "print(\"----------duplicated value check ------------\")\n",
    "\n",
    "print(\"dpulicated value detected:{}\".format(data.duplicated().sum())) \n",
    "\"\"\"\n",
    "#1.1 prepare return data\n",
    "rtn_data = pd.DataFrame()\n",
    "for col in data.columns:\n",
    "    if col == \"Date\":\n",
    "        rtn_data[\"Date\"] = data[col]\n",
    "    else:\n",
    "        rtn_data[\"{}_rtn\".format(col)] = data[col].pct_change(1) * 100        \n",
    "rtn_data.dropna(inplace = True) # drop the first row as we can't find rtn for the first date.\n",
    "\n",
    "\n",
    "#2. Data set split\n",
    "cut_off_date=\"2022-01-01\" #Use 2022-01-01 as a cutoff date.\n",
    "train_data = rtn_data[rtn_data[\"Date\"]<cut_off_date]\n",
    "test_data = rtn_data[rtn_data[\"Date\"]>=cut_off_date]\n",
    "#print(\"train data shape: {}, test data shape: {} \".format(train_data.shape,test_data.shape))\n",
    "\n",
    "\n",
    "#3. fit the model\n",
    "assets = []\n",
    "for col in rtn_data.columns:\n",
    "    if col !=\"Date\" and col != \"DIA_rtn\":\n",
    "        assets.append(col)\n",
    "        \n",
    "daily_rf = (1+0.05482)**(1/365) - 1  #annual_rf = 5.482% per the annualized U.S. 3-month Treasury Bill yield\n",
    "safe_assets =[]\n",
    "for asset in assets:\n",
    "    Y = train_data[asset] - daily_rf\n",
    "    X = train_data[\"DIA_rtn\"] - daily_rf\n",
    "    model = sm.OLS(Y,X)\n",
    "    result = model.fit() \n",
    "    p_value = result.pvalues[0]\n",
    "    beta=result.params[0]\n",
    "    if p_value < 0.05 and 0.85 < beta < 1.15:\n",
    "        safe_assets.append(asset[0:-4])\n",
    "\n",
    "print(safe_assets)\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62a69662-c7d6-4ded-8fee-05de895ed868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>BA.N_rtn</td>     <th>  R-squared (uncentered):</th>      <td>   0.512</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.511</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   1208.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 22 Sep 2023</td> <th>  Prob (F-statistic):</th>          <td>1.10e-181</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:36:41</td>     <th>  Log-Likelihood:    </th>          <td> -2523.7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1154</td>      <th>  AIC:               </th>          <td>   5049.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1153</td>      <th>  BIC:               </th>          <td>   5055.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIA_rtn</th> <td>    1.6800</td> <td>    0.048</td> <td>   34.761</td> <td> 0.000</td> <td>    1.585</td> <td>    1.775</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>394.036</td> <th>  Durbin-Watson:     </th> <td>   1.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>9055.425</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.023</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.570</td>  <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &    BA.N\\_rtn     & \\textbf{  R-squared (uncentered):}      &     0.512   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.511   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     1208.   \\\\\n",
       "\\textbf{Date:}             & Fri, 22 Sep 2023 & \\textbf{  Prob (F-statistic):}          & 1.10e-181   \\\\\n",
       "\\textbf{Time:}             &     12:36:41     & \\textbf{  Log-Likelihood:    }          &   -2523.7   \\\\\n",
       "\\textbf{No. Observations:} &        1154      & \\textbf{  AIC:               }          &     5049.   \\\\\n",
       "\\textbf{Df Residuals:}     &        1153      & \\textbf{  BIC:               }          &     5055.   \\\\\n",
       "\\textbf{Df Model:}         &           1      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                  & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{DIA\\_rtn} &       1.6800  &        0.048     &    34.761  &         0.000        &        1.585    &        1.775     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 394.036 & \\textbf{  Durbin-Watson:     } &    1.896  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 9055.425  \\\\\n",
       "\\textbf{Skew:}          &   1.023 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.570 & \\textbf{  Cond. No.          } &     1.00  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:               BA.N_rtn   R-squared (uncentered):                   0.512\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.511\n",
       "Method:                 Least Squares   F-statistic:                              1208.\n",
       "Date:                Fri, 22 Sep 2023   Prob (F-statistic):                   1.10e-181\n",
       "Time:                        12:36:41   Log-Likelihood:                         -2523.7\n",
       "No. Observations:                1154   AIC:                                      5049.\n",
       "Df Residuals:                    1153   BIC:                                      5055.\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "DIA_rtn        1.6800      0.048     34.761      0.000       1.585       1.775\n",
       "==============================================================================\n",
       "Omnibus:                      394.036   Durbin-Watson:                   1.896\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9055.425\n",
       "Skew:                           1.023   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.570   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e33509-f970-4a7d-9c3c-ca7a97ccde8a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Task 2 - Select a subset of constituents and fit a predictive linear model to forecast the index value (*40 points*)\n",
    "\n",
    "In this task, you will apply linear predictive modeling techniques to forecast the value of the DIA ETF on the DJIA index using the subset of its constituents you selected in the previous task. The goal is to build a predictive linear model that accurately estimates the future index return based on the historical data of selected constituent stocks. Note that to perform this predictive task, you have to prepare the data accordingly. Don't use the excess returns with respect to a daily risk-free rate for this task, but use the plain returns instead.\n",
    "\n",
    "The predictive linear regression equation to estimate the dependent variable \\(Y\\) at time \\(t+1\\) is represented as:\n",
    "\n",
    "$$ Y_{t+1} = \\beta_0 + \\beta_1 X_{1,t} + \\beta_2 X_{2,t} + \\ldots + \\beta_k X_{k,t} + \\varepsilon_{t} $$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "- $Y_{t+1}$ represents the dependent variable at time $t+1$ that we want to predict. Note that the dependent variable is real-valued.\n",
    "- $\\beta_0$ is the intercept or constant term.\n",
    "- $\\beta_1, \\beta_2, \\ldots, \\beta_k$ are the $k$ coefficients for the independent variables $ X_{1,t}, X_{2,t}, \\ldots, X_{k,t} $ at time $t$. you can assume $k$ to be the number of selected stocks from the previous task. Note that the regressors are real-valued.\n",
    "- $\\varepsilon_{t}$ represents the error term at time $t$, capturing unexplained variation or noise in the dependent variable at that specific time.\n",
    "\n",
    "Before performing the linear regression modeling, remember to split the dataset into a training set and a test set. Use *2022-01-01* as a cutoff date, the same way you did in the previous task. Make sure the cutoff date will be included in the test set and not in the train set.\n",
    "\n",
    "Assess the performance of your predictive model using an appropriate evaluation metric for a regression problem like this one. Evaluate the model on the test set to ensure its predictive accuracy out-of-sample.\n",
    "\n",
    "**Grading Criteria**\n",
    "\n",
    "- **Data Preparation (15 points)**: Points will be awarded for preparing the data appropriately for the modeling task.\n",
    "\n",
    "- **Predictive Regression Model Building (20 points)**: Points will be awarded based on the correctness and completeness of the regression model built using selected stocks' returns and the index return.\n",
    "\n",
    "- **Model Evaluation (5 points)**: Points will be awarded based on the proper choice of evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f12a3ac2-68c5-4268-a2d5-f016ef179b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for the test set:1.4554\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "#0.data preparation\n",
    "data = pd.read_csv(\"dows_daily.csv\")\n",
    "\n",
    "#0.1 prepare return data\n",
    "rtn_data = pd.DataFrame()\n",
    "for col in data.columns:\n",
    "    if col == \"Date\":\n",
    "        rtn_data[\"Date\"] = data[col]\n",
    "    else:\n",
    "        rtn_data[\"{}_rtn\".format(col)] = data[col].pct_change(1) * 100        \n",
    "rtn_data.dropna(inplace = True) # drop the first row as we can't find rtn for the first date.\n",
    "\n",
    "#0.2 Dataset split\n",
    "cut_off_date=\"2022-01-01\" #Use 2022-01-01 as a cutoff date.\n",
    "train_data = rtn_data[rtn_data[\"Date\"]<cut_off_date]\n",
    "test_data = rtn_data[rtn_data[\"Date\"]>=cut_off_date]\n",
    "\n",
    "#0.3 derive X and Y\n",
    "Y = train_data[\"DIA_rtn\"].shift(-1).dropna()\n",
    "X = train_data.loc[:, [asset + \"_rtn\" for asset in safe_assets]].iloc[0:-1,:]\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "#1.fit the model\n",
    "model = sm.OLS(Y,X)\n",
    "result = model.fit()\n",
    "result.summary()\n",
    "\n",
    "\n",
    "\n",
    "#2.test \n",
    "test_X = test_data.loc[:, [asset + \"_rtn\" for asset in safe_assets]].iloc[0:-1,:]\n",
    "test_X = sm.add_constant(test_X)\n",
    "\n",
    "test_Y_hat = result.predict(test_X)\n",
    "test_Y = test_data[\"DIA_rtn\"].shift(-1).dropna()\n",
    "test_mse = ((test_Y - test_Y_hat)**2).mean()\n",
    "\n",
    "print(\"MSE for the test set:{}\".format(round(test_mse,4)))\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a09cd8-0d9f-49d7-84a5-7e6640e527a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>DIA_rtn</td>     <th>  R-squared:         </th> <td>   0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 22 Sep 2023</td> <th>  Prob (F-statistic):</th> <td>4.24e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:36:41</td>     <th>  Log-Likelihood:    </th> <td> -1906.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1153</td>      <th>  AIC:               </th> <td>   3844.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1137</td>      <th>  BIC:               </th> <td>   3925.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td>    0.0717</td> <td>    0.038</td> <td>    1.897</td> <td> 0.058</td> <td>   -0.002</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NKE.N_rtn</th>   <td>    0.0185</td> <td>    0.026</td> <td>    0.708</td> <td> 0.479</td> <td>   -0.033</td> <td>    0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CSCO.OQ_rtn</th> <td>   -0.0150</td> <td>    0.034</td> <td>   -0.442</td> <td> 0.659</td> <td>   -0.082</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS.N_rtn</th>   <td>   -0.0175</td> <td>    0.027</td> <td>   -0.645</td> <td> 0.519</td> <td>   -0.071</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INTC.OQ_rtn</th> <td>   -0.0246</td> <td>    0.023</td> <td>   -1.075</td> <td> 0.283</td> <td>   -0.070</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HD.N_rtn</th>    <td>    0.0878</td> <td>    0.034</td> <td>    2.610</td> <td> 0.009</td> <td>    0.022</td> <td>    0.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UNH.N_rtn</th>   <td>   -0.0428</td> <td>    0.028</td> <td>   -1.551</td> <td> 0.121</td> <td>   -0.097</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MSFT.OQ_rtn</th> <td>   -0.1007</td> <td>    0.042</td> <td>   -2.376</td> <td> 0.018</td> <td>   -0.184</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HON.OQ_rtn</th>  <td>    0.0134</td> <td>    0.043</td> <td>    0.314</td> <td> 0.753</td> <td>   -0.070</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRM.N_rtn</th>   <td>    0.0034</td> <td>    0.025</td> <td>    0.136</td> <td> 0.892</td> <td>   -0.045</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IBM.N_rtn</th>   <td>   -0.0050</td> <td>    0.031</td> <td>   -0.159</td> <td> 0.873</td> <td>   -0.066</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MMM.N_rtn</th>   <td>   -0.0464</td> <td>    0.036</td> <td>   -1.304</td> <td> 0.192</td> <td>   -0.116</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AAPL.OQ_rtn</th> <td>   -0.0288</td> <td>    0.030</td> <td>   -0.971</td> <td> 0.332</td> <td>   -0.087</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CAT.N_rtn</th>   <td>    0.0541</td> <td>    0.028</td> <td>    1.901</td> <td> 0.057</td> <td>   -0.002</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V.N_rtn</th>     <td>   -0.0151</td> <td>    0.039</td> <td>   -0.388</td> <td> 0.698</td> <td>   -0.092</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TRV.N_rtn</th>   <td>   -0.0966</td> <td>    0.029</td> <td>   -3.277</td> <td> 0.001</td> <td>   -0.154</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>390.064</td> <th>  Durbin-Watson:     </th> <td>   1.967</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>13100.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.892</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.416</td>  <th>  Cond. No.          </th> <td>    6.83</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &     DIA\\_rtn     & \\textbf{  R-squared:         } &     0.073   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.061   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     5.964   \\\\\n",
       "\\textbf{Date:}             & Fri, 22 Sep 2023 & \\textbf{  Prob (F-statistic):} &  4.24e-12   \\\\\n",
       "\\textbf{Time:}             &     12:36:41     & \\textbf{  Log-Likelihood:    } &   -1906.2   \\\\\n",
       "\\textbf{No. Observations:} &        1153      & \\textbf{  AIC:               } &     3844.   \\\\\n",
       "\\textbf{Df Residuals:}     &        1137      & \\textbf{  BIC:               } &     3925.   \\\\\n",
       "\\textbf{Df Model:}         &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}        &       0.0717  &        0.038     &     1.897  &         0.058        &       -0.002    &        0.146     \\\\\n",
       "\\textbf{NKE.N\\_rtn}   &       0.0185  &        0.026     &     0.708  &         0.479        &       -0.033    &        0.070     \\\\\n",
       "\\textbf{CSCO.OQ\\_rtn} &      -0.0150  &        0.034     &    -0.442  &         0.659        &       -0.082    &        0.052     \\\\\n",
       "\\textbf{DIS.N\\_rtn}   &      -0.0175  &        0.027     &    -0.645  &         0.519        &       -0.071    &        0.036     \\\\\n",
       "\\textbf{INTC.OQ\\_rtn} &      -0.0246  &        0.023     &    -1.075  &         0.283        &       -0.070    &        0.020     \\\\\n",
       "\\textbf{HD.N\\_rtn}    &       0.0878  &        0.034     &     2.610  &         0.009        &        0.022    &        0.154     \\\\\n",
       "\\textbf{UNH.N\\_rtn}   &      -0.0428  &        0.028     &    -1.551  &         0.121        &       -0.097    &        0.011     \\\\\n",
       "\\textbf{MSFT.OQ\\_rtn} &      -0.1007  &        0.042     &    -2.376  &         0.018        &       -0.184    &       -0.018     \\\\\n",
       "\\textbf{HON.OQ\\_rtn}  &       0.0134  &        0.043     &     0.314  &         0.753        &       -0.070    &        0.097     \\\\\n",
       "\\textbf{CRM.N\\_rtn}   &       0.0034  &        0.025     &     0.136  &         0.892        &       -0.045    &        0.052     \\\\\n",
       "\\textbf{IBM.N\\_rtn}   &      -0.0050  &        0.031     &    -0.159  &         0.873        &       -0.066    &        0.056     \\\\\n",
       "\\textbf{MMM.N\\_rtn}   &      -0.0464  &        0.036     &    -1.304  &         0.192        &       -0.116    &        0.023     \\\\\n",
       "\\textbf{AAPL.OQ\\_rtn} &      -0.0288  &        0.030     &    -0.971  &         0.332        &       -0.087    &        0.029     \\\\\n",
       "\\textbf{CAT.N\\_rtn}   &       0.0541  &        0.028     &     1.901  &         0.057        &       -0.002    &        0.110     \\\\\n",
       "\\textbf{V.N\\_rtn}     &      -0.0151  &        0.039     &    -0.388  &         0.698        &       -0.092    &        0.062     \\\\\n",
       "\\textbf{TRV.N\\_rtn}   &      -0.0966  &        0.029     &    -3.277  &         0.001        &       -0.154    &       -0.039     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 390.064 & \\textbf{  Durbin-Watson:     } &     1.967  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 13100.177  \\\\\n",
       "\\textbf{Skew:}          &  -0.892 & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.416 & \\textbf{  Cond. No.          } &      6.83  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                DIA_rtn   R-squared:                       0.073\n",
       "Model:                            OLS   Adj. R-squared:                  0.061\n",
       "Method:                 Least Squares   F-statistic:                     5.964\n",
       "Date:                Fri, 22 Sep 2023   Prob (F-statistic):           4.24e-12\n",
       "Time:                        12:36:41   Log-Likelihood:                -1906.2\n",
       "No. Observations:                1153   AIC:                             3844.\n",
       "Df Residuals:                    1137   BIC:                             3925.\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const           0.0717      0.038      1.897      0.058      -0.002       0.146\n",
       "NKE.N_rtn       0.0185      0.026      0.708      0.479      -0.033       0.070\n",
       "CSCO.OQ_rtn    -0.0150      0.034     -0.442      0.659      -0.082       0.052\n",
       "DIS.N_rtn      -0.0175      0.027     -0.645      0.519      -0.071       0.036\n",
       "INTC.OQ_rtn    -0.0246      0.023     -1.075      0.283      -0.070       0.020\n",
       "HD.N_rtn        0.0878      0.034      2.610      0.009       0.022       0.154\n",
       "UNH.N_rtn      -0.0428      0.028     -1.551      0.121      -0.097       0.011\n",
       "MSFT.OQ_rtn    -0.1007      0.042     -2.376      0.018      -0.184      -0.018\n",
       "HON.OQ_rtn      0.0134      0.043      0.314      0.753      -0.070       0.097\n",
       "CRM.N_rtn       0.0034      0.025      0.136      0.892      -0.045       0.052\n",
       "IBM.N_rtn      -0.0050      0.031     -0.159      0.873      -0.066       0.056\n",
       "MMM.N_rtn      -0.0464      0.036     -1.304      0.192      -0.116       0.023\n",
       "AAPL.OQ_rtn    -0.0288      0.030     -0.971      0.332      -0.087       0.029\n",
       "CAT.N_rtn       0.0541      0.028      1.901      0.057      -0.002       0.110\n",
       "V.N_rtn        -0.0151      0.039     -0.388      0.698      -0.092       0.062\n",
       "TRV.N_rtn      -0.0966      0.029     -3.277      0.001      -0.154      -0.039\n",
       "==============================================================================\n",
       "Omnibus:                      390.064   Durbin-Watson:                   1.967\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13100.177\n",
       "Skew:                          -0.892   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.416   Cond. No.                         6.83\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aee638-53a5-41ce-8ac6-9c6f030870af",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "source": [
    "## Task 3 - Augment the Dataset with Bootstrapped Alphas and Fit again the Linear Predictive Models (40 points)\n",
    "\n",
    "In this task, we explore the concept of bootstrapped alphas and their role in predictive modeling. Bootstrapped alphas are used as proxy trading signals for real alphas that can be practically obtained. These signals are correlated with future returns and can play the role of good predictors in the predictive modeling process. Don't use the excess returns with respect to a daily risk-free rate for this task, but use the plain returns instead when you have to calculate the boostrapped alphas.\n",
    "\n",
    "We define bootstrapped alphas $\\alpha_t$ as per the formula below:\n",
    "\n",
    "$$\\alpha_{i,t} := \\rho_{\\text{boot}} r_{i,t+1} + \\sqrt{1 - \\rho_{\\text{boot}}^{2}} z_{i,t}$$\n",
    "\n",
    "where:\n",
    "- $r_{i,t+1}$ represents the next period return of the traded security $i$, which is given to you.\n",
    "- $z_{i,t} \\sim \\mathbb{N}(0,\\sigma^{2})$ is a randomly drawn scalar associated for each company $i$, which is not given and you have to sample. When sampling, ensure that each sampled vector is independent of the other since you have to draw samples for each company you will use as regressors. The number of companies stays the same that you used in the previous task and that you have selected by fitting the CAPM model in task 1.\n",
    "- $\\sigma^{2}_{i}$ is an estimate of the true conditional variance of the security $i$, which you have to calculate based on the given returns. Note that you have to calculate those variances on the train set only. Use the same cutoff applied in the previous task to define what the training set is.\n",
    "- $\\rho_{\\text{boot}} \\in [-1,1]$ is a correlation coefficient, which you have to set equal to 0.25.\n",
    "\n",
    "In this setting, the parameter $\\rho_{\\text{boot}}$ artificially regulates the strength of the trading signal you create. We remark that regressing the bootstrapped alpha $\\alpha_t$ on the future returns $r_{t+1}$ results in an $R^2$ equal to $\\rho^2$.\n",
    "\n",
    "The equation above formalizes the calculation of the boostrapped alpha for a single security while you will have more than one security. Try to make your calculations as efficient as possible by computing them simultaneously. It is possible by using calculations between pandas dataframe. Remember that $z_{i,t} \\sim \\mathcal{N}(0,\\sigma^{2}_{i})$ can be calculated as $z_{i,t} = \\sqrt{\\sigma^{2}_{i}}u_{i,t}$ where $u_{i,t} \\sim \\mathcal{N}(0,1)$. \n",
    "\n",
    "Once you calculate the boostrapped alphas, repeat the linear predictive forecasting exercise as in the previous task. This time you will use the boostrapped alphas as predictors, while you will keep the same target as before, the index returns. In other words, the target stays the same as in the previous task (future returns for DIA) by looking at the equation below. Still, the predictors change from the current returns of the constituents to the alpha bootstrap you have calculated.\n",
    "\n",
    "$$ Y_{t+1} = \\beta_0 + \\beta_1 X_{1,t} + \\beta_2 X_{2,t} + \\ldots + \\beta_k X_{k,t} + \\varepsilon_{t} $$\n",
    "\n",
    "To ensure reproducibility, please set the random seed to 42. Don't use another seed, and remember to set it. Avoiding to follow these guidelines will result in point deductions.\n",
    "\n",
    "**Motivation behind the task**\n",
    "\n",
    "In the dynamic and complex world of financial markets, predictive modeling is a potent tool to decipher underlying patterns and trends that govern security prices. Coming up with good predictors for a certain set of assets is a complicated task that is not necessarily the purpose of this assignment. The concept of bootstrapped alphas, as delineated in this exercise, emerges as a sophisticated method to engineer artificial trading signals that can potentially enhance the predictive power of financial models. It is equivalent to assuming that we have a way to predict the future returns of the index constituents. Look at the alpha bootstrap equation to understand why we are talking about future returns by looking at what the prices indicate.\n",
    "\n",
    "The utilization of bootstrapped alphas is grounded in the mathematical formulation provided, where the alpha ($\\alpha_{i,t}$) for a security $i$ at time $t$ is constructed using a combination of the next period return of the security ($r_{i,t+1}$) and a stochastic component ($z_{i,t}$) drawn from a normal distribution. This formulation allows for the incorporation of both deterministic and random elements, thereby mimicking the inherent uncertainty and volatility observed in financial markets.\n",
    "\n",
    "By setting the correlation coefficient ($\\rho_{\\text{boot}}$) to 0.25, we are essentially moderating the influence of the artificial trading signal, ensuring that it does not overwhelmingly dictate the behavior of the bootstrapped alphas. This parameter, therefore, serves as a tuning knob, allowing us to control the strength of the trading signal and, consequently, its predictive power. However, you have to keep this parameter fixed for this exercise, as indicated by the prompt.\n",
    "\n",
    "The subsequent step of employing these bootstrapped alphas as predictors in a linear predictive forecasting model is an exercise to highlight how well one can expect to forecast index returns, given a good way to predict future returns for the constituents. By replacing the current returns of the constituents with the calculated bootstrapped alphas, we are essentially enhancing the model with artificially generated yet statistically grounded signals that can potentially unveil deeper insights into the market dynamics.\n",
    "\n",
    "**Grading Criteria**\n",
    "\n",
    "- **Data Preparation (30 points)**: Points will be awarded for preparing the data appropriately for the modeling task.\n",
    "\n",
    "- **Predictive Regression Model Building (5 points)**: Points will be awarded based on the correctness and completeness of the regression model built using selected stocks' boostrapped alpha and the index return.\n",
    "- **Model Evaluation (5 points)**: Points will be awarded based on the proper choice of evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2382133-ac60-4d82-84c2-048ccabad403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's Adjusted R square: 0.3415\n",
      "MSE for the test set: 0.8585\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "np.random.seed(42)\n",
    "\n",
    "#0.data preparation\n",
    "data = pd.read_csv(\"dows_daily.csv\")\n",
    "data = data[[\"Date\",\"DIA\"]+safe_assets] #safe_assets is from task1\n",
    "#0.1 prepare return data\n",
    "rtn_data = pd.DataFrame()\n",
    "for col in data.columns:\n",
    "    if col == \"Date\":\n",
    "        rtn_data[\"Date\"] = data[col]\n",
    "    else:\n",
    "        rtn_data[col] = data[col].pct_change(1) * 100    \n",
    "\n",
    "rtn_data.dropna(inplace = True) # drop the first row as we can't find rtn for the first date.\n",
    "rtn_data.reset_index(inplace = True,drop=True)\n",
    "\n",
    "\n",
    "#0.2 bootstrapped alpha\n",
    "rho_boot = 0.25\n",
    "cut_off_date=\"2022-01-01\" #Use 2022-01-01 as a cutoff date.\n",
    "\n",
    "#0.2.1 random component \n",
    "sigma = rtn_data[rtn_data[\"Date\"]<cut_off_date].iloc[:,2:].std() #caculate conditional variance sigma for securities\n",
    "norm_dist_var = pd.DataFrame(np.random.normal(0,1,[rtn_data.shape[0],rtn_data.shape[1]-2])) # generate u~N(0,1),ignore the first two columns Date and DIA\n",
    "z = sigma.values * norm_dist_var\n",
    "random_component = ((1-rho_boot**2)**(1/2)*z)\n",
    "new_columns = rtn_data.columns[2:]\n",
    "random_component.columns = new_columns\n",
    "\n",
    "#0.2.2 fixed component\n",
    "fixed_component = rho_boot * rtn_data.iloc[:,2:]\n",
    "fixed_component.reset_index(inplace = True,drop=True)\n",
    "\n",
    "#0.2.3 calculate bootstrapped alpha\n",
    "bsa_data = pd.DataFrame()# \"bsa\" stands for bootstrapped alpha\n",
    "bsa_data = fixed_component + random_component\n",
    "\n",
    "#1. split again on processed bootstrapped alpha data set\n",
    "train_data = bsa_data[rtn_data[\"Date\"]<cut_off_date] #(1154,30) Date DIA XXXX....\n",
    "test_data = bsa_data[rtn_data[\"Date\"]>=cut_off_date] #(356,30) Date DIA XXXX...\n",
    "\n",
    "#2.fit the model\n",
    "X = sm.add_constant(train_data)\n",
    "Y = rtn_data[rtn_data[\"Date\"]<cut_off_date][\"DIA\"]\n",
    "Y.reset_index(inplace = True,drop=True)\n",
    "model = sm.OLS(Y,X)\n",
    "result = model.fit()\n",
    "\n",
    "#3. predict the test set\n",
    "test_X = sm.add_constant(test_data)\n",
    "test_Y_hat = result.predict(test_X)\n",
    "test_data.reset_index(inplace = True,drop=True)\n",
    "test_Y = rtn_data[rtn_data[\"Date\"]>=cut_off_date][\"DIA\"]\n",
    "\n",
    "#4. Evaluation metrics\n",
    "test_mse = ((test_Y - test_Y_hat)**2).mean()\n",
    "print(\"Model's Adjusted R square: {}\".format(round(result.rsquared_adj,4)))\n",
    "print(\"MSE for the test set: {}\".format(round(test_mse,4)))\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676208bf-6432-474a-88ab-2f52bb27bedb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>DIA</td>       <th>  R-squared:         </th> <td>   0.350</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.341</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   40.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 22 Sep 2023</td> <th>  Prob (F-statistic):</th> <td>1.68e-95</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:36:41</td>     <th>  Log-Likelihood:    </th> <td> -1702.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1154</td>      <th>  AIC:               </th> <td>   3437.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1138</td>      <th>  BIC:               </th> <td>   3518.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>    0.0209</td> <td>    0.032</td> <td>    0.660</td> <td> 0.510</td> <td>   -0.041</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NKE.N</th>   <td>    0.0805</td> <td>    0.016</td> <td>    4.988</td> <td> 0.000</td> <td>    0.049</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CSCO.OQ</th> <td>    0.0999</td> <td>    0.018</td> <td>    5.606</td> <td> 0.000</td> <td>    0.065</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS.N</th>   <td>    0.0650</td> <td>    0.017</td> <td>    3.773</td> <td> 0.000</td> <td>    0.031</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INTC.OQ</th> <td>    0.0705</td> <td>    0.014</td> <td>    5.141</td> <td> 0.000</td> <td>    0.044</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HD.N</th>    <td>    0.0929</td> <td>    0.019</td> <td>    4.905</td> <td> 0.000</td> <td>    0.056</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UNH.N</th>   <td>    0.0993</td> <td>    0.017</td> <td>    5.894</td> <td> 0.000</td> <td>    0.066</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MSFT.OQ</th> <td>    0.1205</td> <td>    0.018</td> <td>    6.681</td> <td> 0.000</td> <td>    0.085</td> <td>    0.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>HON.OQ</th>  <td>    0.1424</td> <td>    0.019</td> <td>    7.611</td> <td> 0.000</td> <td>    0.106</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRM.N</th>   <td>    0.0884</td> <td>    0.015</td> <td>    5.911</td> <td> 0.000</td> <td>    0.059</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IBM.N</th>   <td>    0.0995</td> <td>    0.019</td> <td>    5.205</td> <td> 0.000</td> <td>    0.062</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MMM.N</th>   <td>    0.0935</td> <td>    0.019</td> <td>    4.861</td> <td> 0.000</td> <td>    0.056</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AAPL.OQ</th> <td>    0.0670</td> <td>    0.016</td> <td>    4.222</td> <td> 0.000</td> <td>    0.036</td> <td>    0.098</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CAT.N</th>   <td>    0.0693</td> <td>    0.015</td> <td>    4.493</td> <td> 0.000</td> <td>    0.039</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V.N</th>     <td>    0.0994</td> <td>    0.018</td> <td>    5.530</td> <td> 0.000</td> <td>    0.064</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TRV.N</th>   <td>    0.0972</td> <td>    0.018</td> <td>    5.404</td> <td> 0.000</td> <td>    0.062</td> <td>    0.132</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>186.038</td> <th>  Durbin-Watson:     </th> <td>   2.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2759.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.178</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>10.568</td>  <th>  Cond. No.          </th> <td>    2.45</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       DIA        & \\textbf{  R-squared:         } &     0.350   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.341   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     40.86   \\\\\n",
       "\\textbf{Date:}             & Fri, 22 Sep 2023 & \\textbf{  Prob (F-statistic):} &  1.68e-95   \\\\\n",
       "\\textbf{Time:}             &     12:36:41     & \\textbf{  Log-Likelihood:    } &   -1702.5   \\\\\n",
       "\\textbf{No. Observations:} &        1154      & \\textbf{  AIC:               } &     3437.   \\\\\n",
       "\\textbf{Df Residuals:}     &        1138      & \\textbf{  BIC:               } &     3518.   \\\\\n",
       "\\textbf{Df Model:}         &          15      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                 & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}   &       0.0209  &        0.032     &     0.660  &         0.510        &       -0.041    &        0.083     \\\\\n",
       "\\textbf{NKE.N}   &       0.0805  &        0.016     &     4.988  &         0.000        &        0.049    &        0.112     \\\\\n",
       "\\textbf{CSCO.OQ} &       0.0999  &        0.018     &     5.606  &         0.000        &        0.065    &        0.135     \\\\\n",
       "\\textbf{DIS.N}   &       0.0650  &        0.017     &     3.773  &         0.000        &        0.031    &        0.099     \\\\\n",
       "\\textbf{INTC.OQ} &       0.0705  &        0.014     &     5.141  &         0.000        &        0.044    &        0.097     \\\\\n",
       "\\textbf{HD.N}    &       0.0929  &        0.019     &     4.905  &         0.000        &        0.056    &        0.130     \\\\\n",
       "\\textbf{UNH.N}   &       0.0993  &        0.017     &     5.894  &         0.000        &        0.066    &        0.132     \\\\\n",
       "\\textbf{MSFT.OQ} &       0.1205  &        0.018     &     6.681  &         0.000        &        0.085    &        0.156     \\\\\n",
       "\\textbf{HON.OQ}  &       0.1424  &        0.019     &     7.611  &         0.000        &        0.106    &        0.179     \\\\\n",
       "\\textbf{CRM.N}   &       0.0884  &        0.015     &     5.911  &         0.000        &        0.059    &        0.118     \\\\\n",
       "\\textbf{IBM.N}   &       0.0995  &        0.019     &     5.205  &         0.000        &        0.062    &        0.137     \\\\\n",
       "\\textbf{MMM.N}   &       0.0935  &        0.019     &     4.861  &         0.000        &        0.056    &        0.131     \\\\\n",
       "\\textbf{AAPL.OQ} &       0.0670  &        0.016     &     4.222  &         0.000        &        0.036    &        0.098     \\\\\n",
       "\\textbf{CAT.N}   &       0.0693  &        0.015     &     4.493  &         0.000        &        0.039    &        0.100     \\\\\n",
       "\\textbf{V.N}     &       0.0994  &        0.018     &     5.530  &         0.000        &        0.064    &        0.135     \\\\\n",
       "\\textbf{TRV.N}   &       0.0972  &        0.018     &     5.404  &         0.000        &        0.062    &        0.132     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 186.038 & \\textbf{  Durbin-Watson:     } &    2.236  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2759.881  \\\\\n",
       "\\textbf{Skew:}          &  -0.178 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  10.568 & \\textbf{  Cond. No.          } &     2.45  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    DIA   R-squared:                       0.350\n",
       "Model:                            OLS   Adj. R-squared:                  0.341\n",
       "Method:                 Least Squares   F-statistic:                     40.86\n",
       "Date:                Fri, 22 Sep 2023   Prob (F-statistic):           1.68e-95\n",
       "Time:                        12:36:41   Log-Likelihood:                -1702.5\n",
       "No. Observations:                1154   AIC:                             3437.\n",
       "Df Residuals:                    1138   BIC:                             3518.\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0209      0.032      0.660      0.510      -0.041       0.083\n",
       "NKE.N          0.0805      0.016      4.988      0.000       0.049       0.112\n",
       "CSCO.OQ        0.0999      0.018      5.606      0.000       0.065       0.135\n",
       "DIS.N          0.0650      0.017      3.773      0.000       0.031       0.099\n",
       "INTC.OQ        0.0705      0.014      5.141      0.000       0.044       0.097\n",
       "HD.N           0.0929      0.019      4.905      0.000       0.056       0.130\n",
       "UNH.N          0.0993      0.017      5.894      0.000       0.066       0.132\n",
       "MSFT.OQ        0.1205      0.018      6.681      0.000       0.085       0.156\n",
       "HON.OQ         0.1424      0.019      7.611      0.000       0.106       0.179\n",
       "CRM.N          0.0884      0.015      5.911      0.000       0.059       0.118\n",
       "IBM.N          0.0995      0.019      5.205      0.000       0.062       0.137\n",
       "MMM.N          0.0935      0.019      4.861      0.000       0.056       0.131\n",
       "AAPL.OQ        0.0670      0.016      4.222      0.000       0.036       0.098\n",
       "CAT.N          0.0693      0.015      4.493      0.000       0.039       0.100\n",
       "V.N            0.0994      0.018      5.530      0.000       0.064       0.135\n",
       "TRV.N          0.0972      0.018      5.404      0.000       0.062       0.132\n",
       "==============================================================================\n",
       "Omnibus:                      186.038   Durbin-Watson:                   2.236\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2759.881\n",
       "Skew:                          -0.178   Prob(JB):                         0.00\n",
       "Kurtosis:                      10.568   Cond. No.                         2.45\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classenv",
   "language": "python",
   "name": "classenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
